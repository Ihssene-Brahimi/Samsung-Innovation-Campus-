{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGP5lyY8EVCN"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf_9nCI8EaA9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "#--------------------------------------------------------------\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAnqcPhDEYxK"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7D6fEgqD_dO",
        "outputId": "3594ee7e-36d1-44e6-e252-4f0da20da525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-09-07 12:57:15--  http://files.fast.ai/data/dogscats.zip\n",
            "Resolving files.fast.ai (files.fast.ai)... 172.67.69.159, 104.26.2.19, 104.26.3.19, ...\n",
            "Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.fast.ai/data/dogscats.zip [following]\n",
            "--2021-09-07 12:57:15--  https://files.fast.ai/data/dogscats.zip\n",
            "Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2021-09-07 12:57:15 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://files.fast.ai/data/dogscats.zip # a folder with cat and dog images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BytIJkvkEHUe",
        "outputId": "e1944a31-1e83-455f-971c-fae6d4cbbac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open dogscats.zip, dogscats.zip.zip or dogscats.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip dogscats.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8t1IAkLQEO2o"
      },
      "outputs": [],
      "source": [
        "PATH = \"dogscats/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypapYCMHWgHl",
        "outputId": "d9e9af84-5d09-47fc-a0ab-0d9616df89a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNL4021HWgPo",
        "outputId": "4a6ea6b7-2c5f-4175-ed3d-245f8f8d0971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PATH = '/content/drive/MyDrive/AI_SIC_PROJECT/DataSets/day/'  #change dir to your project folder\n",
        "files = glob.glob(PATH+'fire_images/*')\n",
        "cat_train = [fn for fn in files]\n",
        "files = glob.glob(PATH+'nonfire_images/*')\n",
        "dog_train = [fn for fn in files]\n",
        "len(cat_train), len(dog_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WATW0GVoERWL",
        "outputId": "38e6a6c4-ca04-4359-8cd5-bc2378c3d535"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# files = glob.glob(PATH+'train/cats/*')\n",
        "# cat_train = [fn for fn in files if 'cat' in fn]\n",
        "# files = glob.glob(PATH+'train/dogs/*')\n",
        "# dog_train = [fn for fn in files if 'dog' in fn]\n",
        "# len(cat_train), len(dog_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7EnLSEuW5af",
        "outputId": "d858c245-a2ec-4b99-9b6f-60954300b76f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PATH = '/content/drive/MyDrive/AI_SIC_PROJECT/DataSets/night/'  #change dir to your project folder\n",
        "files = glob.glob(PATH+'fire/*')\n",
        "cat_val = [fn for fn in files]\n",
        "files = glob.glob(PATH+'nonfire/*')\n",
        "dog_val = [fn for fn in files]\n",
        "len(cat_val), len(dog_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alC2UgIHEmPc",
        "outputId": "1e47bee2-b298-492e-b00e-b14004df4de7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# files = glob.glob(PATH+'valid/cats/*')\n",
        "# cat_val = [fn for fn in files if 'cat' in fn]\n",
        "# files = glob.glob(PATH+'valid/dogs/*')\n",
        "# dog_val = [fn for fn in files if 'dog' in fn]\n",
        "# len(cat_val), len(dog_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAToaZZNExJB"
      },
      "outputs": [],
      "source": [
        "train_files = np.concatenate([cat_train[:200], dog_train[:200]]) # For technical issues we will only use 2000 images for each class\n",
        "validation_files = np.concatenate([cat_val, dog_val])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jx2f_DyGUql"
      },
      "source": [
        "![Texte alternatifâ€¦](https://faunalytics.org/wp-content/uploads/2017/11/14017928228_56f72a1aeb_krecrop-690x325.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUtj1WTwGQcQ"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQSVnCXVE9TB"
      },
      "outputs": [],
      "source": [
        "IMG_DIM = (224, 224)\n",
        "\n",
        "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
        "train_imgs = np.array(train_imgs)\n",
        "train_labels = [fn.split('/')[3].split('.')[0].strip() for fn in train_files]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHGeWQ-YFDYw"
      },
      "outputs": [],
      "source": [
        "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
        "validation_imgs = np.array(validation_imgs)\n",
        "validation_labels = [fn.split('/')[3].split('.')[0].strip() for fn in validation_files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhfxM9spFKNN",
        "outputId": "a23144e1-b1e9-464b-a4b3-c21ca3bbab34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset shape: (0,) \tValidation dataset shape: (0,)\n"
          ]
        }
      ],
      "source": [
        "print('Train dataset shape:', train_imgs.shape, \n",
        "      '\\tValidation dataset shape:', validation_imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIcogl6NFMoC"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "train_labels_enc = le.transform(train_labels)\n",
        "validation_labels_enc = le.transform(validation_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "KcdJBA3VFYj_",
        "outputId": "2194c1f6-b681-4fe6-9c26-dbec5be8bcc1"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cc84cc391482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         subset=subset)\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m   def flow_from_directory(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[1;32m    125\u001b[0m                              \u001b[0;34m'should have rank 4. You passed an array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                              'with shape', self.x.shape)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (0,))"
          ]
        }
      ],
      "source": [
        "# For CNN model (1) we will need rescaled images\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import glob\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#--------------------------------------------------------------\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "train_set = ImageDataGenerator(rescale=1./255).flow(train_imgs, train_labels_enc, batch_size=30)\n",
        "\n",
        "val_set = ImageDataGenerator(rescale=1./255).flow(validation_imgs, validation_labels_enc, batch_size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAS64XfXFfxf"
      },
      "outputs": [],
      "source": [
        "# To improve performance in the second part we will be using VGG model + data augmentation \n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1USYeaeMFxbV"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=30)\n",
        "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eLYvi34F1HD"
      },
      "outputs": [],
      "source": [
        "# See output of data augmentation \n",
        "cat_generator = train_datagen.flow(train_imgs[1120:1121], train_labels[1120:1121],\n",
        "                                   batch_size=1)\n",
        "cat = [next(cat_generator) for i in range(0,5)]\n",
        "fig, ax = plt.subplots(1,5, figsize=(16, 6))\n",
        "print('Labels:', [item[1][0] for item in cat])\n",
        "l = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
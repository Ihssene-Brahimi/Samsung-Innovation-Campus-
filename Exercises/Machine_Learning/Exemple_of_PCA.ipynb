{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln92kYPYEVAG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF3dLkPCEV6J"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "cancer.keys()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YSvOiQVEa9Z"
      },
      "source": [
        "print(cancer['DESCR'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwCrJczNEp4L"
      },
      "source": [
        "# PCA Visualization\n",
        "\n",
        "As we've noticed before it is difficult to visualize high dimensional data, we can use PCA to find the first two principal components, and visualize the data in this new, two-dimensional space, with a single scatter-plot. Before we do this though, we'll need to scale our data so that each feature has a single unit variance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzfh9D5JEdqY"
      },
      "source": [
        "df = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
        "df.head()\n",
        "Y = cancer.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kygTZiGYEmMP"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfJwIwsrE9bh"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(df) #Rescalling all the values in the same scale\n",
        "scaled_data = scaler.transform(df) #with transform all the values are converted to the same scale\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmjOIWceGAN9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D4IgJRsGAjs"
      },
      "source": [
        "#You can use the following command for data scalling\n",
        "from sklearn.preprocessing import scale # For Data Scaling\n",
        "scaled_data = scale(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O7eNLlBDnXq"
      },
      "source": [
        "PCA with Scikit Learn uses a very similar process to other preprocessing functions that come with SciKit Learn. We instantiate a PCA object, find the principal components using the fit method, then apply the rotation and dimensionality reduction by calling transform().\n",
        "\n",
        "We can also specify how many components we want to keep when creating the PCA object, here it s 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVhi5XfJGF6T"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfeO7372GHY-"
      },
      "source": [
        "pca.fit(scaled_data) # we need only our features, since PCA is an unsupervised learning techniques and it doesn't need lables to learn\n",
        "# we will cluster data based on similarity and based on eigen value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmxxF4BTGI-g"
      },
      "source": [
        "x_pca = pca.transform(scaled_data)\n",
        "#let s check the shape of our data before and after applying PCa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfMIrlOYGK6A"
      },
      "source": [
        "scaled_data.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7mxClrFGMh_"
      },
      "source": [
        "x_pca.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1eK4eqKHAFl"
      },
      "source": [
        "scores_df = pd.DataFrame(x_pca, columns=['PC1', 'PC2', 'PC3','PC4'])\n",
        "scores_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_-6D7oKGOB3"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(x_pca[:,0],x_pca[:,1],c=cancer['target'],cmap='plasma')\n",
        "plt.xlabel('First principal component')\n",
        "plt.ylabel('Second Principal Component')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxsB4yVrEeNl"
      },
      "source": [
        "So, for so far, we did the following steps:\n",
        "\n",
        "1- Standar Sclling\n",
        "\n",
        "\n",
        "2- Apply PCA\n",
        "\n",
        "3- convert our data from 30 dimension to 4 dimension.\n",
        "\n",
        "Now we can apply Decision tree, k means ... on our new dataset.\n",
        "What we did is part of data preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BGyp0yaGXiJ"
      },
      "source": [
        "# Interpreting the components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20yqU_yuGctC"
      },
      "source": [
        "Unfortunately, with this great power of dimensionality reduction, comes the cost of being able to easily understand what these components represent.\n",
        "\n",
        "The components correspond to combinations of the original features, the components themselves are stored as an attribute of the fitted PCA object:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D22MxaCAGi1Y"
      },
      "source": [
        "In this numpy matrix array, each row represents a principal component, and each column relates back to the original features. we can visualize this relationship with a heatmap:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57B8J5cKGfHm"
      },
      "source": [
        "df_comp = pd.DataFrame(pca.components_,columns=cancer['feature_names'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U3ulXtFGlBq"
      },
      "source": [
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.heatmap(df_comp,cmap='plasma',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rALopeY9Go6w"
      },
      "source": [
        "This heatmap and the color bar basically represent the correlation between the various feature and the principal component itself.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw6gYMvjGsl7"
      },
      "source": [
        "Hopefully this information is useful to you when dealing with high dimensional data!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO9Q40nbGtuL"
      },
      "source": [
        "\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R102Swuu2IN"
      },
      "source": [
        "#let s see the explained variance\n",
        "#it will tell us what is the contribution of each PC, ie, how much each pc contributes to the overall variance of the data set\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "explained_variance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PmEZzxpu4S8"
      },
      "source": [
        "explained_variance = np.insert(explained_variance, 0, 0) # to force the values to start from 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sFyxe6MvDQR"
      },
      "source": [
        "cumulative_variance = np.cumsum(np.round(explained_variance, decimals=3)) # at each point of the graph show the cumultative variance\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxtTEiRwvE7D"
      },
      "source": [
        "pc_df = pd.DataFrame(['','PC1', 'PC2', 'PC3','PC4'], columns=['PC'])\n",
        "explained_variance_df = pd.DataFrame(explained_variance, columns=['Explained Variance'])\n",
        "cumulative_variance_df = pd.DataFrame(cumulative_variance, columns=['Cumulative Variance'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVdaHpJ-vIq4"
      },
      "source": [
        "df_explained_variance = pd.concat([pc_df, explained_variance_df, cumulative_variance_df], axis=1)\n",
        "df_explained_variance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UYpWNDvvK3T"
      },
      "source": [
        "fig = px.bar(df_explained_variance, \n",
        "             x='PC', y='Explained Variance',\n",
        "             text='Explained Variance',\n",
        "             width=800)\n",
        "\n",
        "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NZq585fv5qa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}